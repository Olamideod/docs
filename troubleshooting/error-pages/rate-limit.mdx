# Rate Limit Error Troubleshooting

This guide helps you understand and resolve rate limiting issues when using Protekt's APIs.

## Understanding Rate Limits

### Default Rate Limits

**API Endpoints:**
- **Authentication endpoints**: 100 requests per minute per IP
- **User management**: 1000 requests per minute per API key
- **Organization management**: 500 requests per minute per API key
- **Webhook endpoints**: 100 requests per minute per webhook URL

**Rate Limit Headers:**
```
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 1640995200
Retry-After: 60
```

### Rate Limit Error Response

```json
{
  "error": "rate_limit_exceeded",
  "error_description": "Rate limit exceeded. Try again in 60 seconds.",
  "retry_after": 60,
  "limit": 100,
  "remaining": 0,
  "reset_time": 1640995200
}
```

## Common Rate Limit Scenarios

### Authentication Rate Limiting

**Symptoms:**
- Login attempts blocked after multiple failures
- "Too many login attempts" error messages
- Account temporarily locked

**Solutions:**

1. **Implement Exponential Backoff**
   ```javascript
   // Exponential backoff for authentication retries
   const loginWithBackoff = async (credentials, maxRetries = 5) => {
     for (let attempt = 1; attempt <= maxRetries; attempt++) {
       try {
         const response = await fetch('https://api.protekt.com/oauth/token', {
           method: 'POST',
           headers: {
             'Content-Type': 'application/json',
           },
           body: JSON.stringify({
             grant_type: 'password',
             username: credentials.username,
             password: credentials.password,
             client_id: 'your-client-id'
           })
         });

         if (response.ok) {
           return await response.json();
         }

         if (response.status === 429) {
           const retryAfter = response.headers.get('Retry-After') || 60;
           const waitTime = Math.min(retryAfter * 1000, Math.pow(2, attempt) * 1000);
           
           console.log(`Rate limited. Waiting ${waitTime}ms before retry ${attempt}`);
           await new Promise(resolve => setTimeout(resolve, waitTime));
           continue;
         }

         throw new Error(`Login failed: ${response.status}`);
       } catch (error) {
         if (attempt === maxRetries) {
           throw error;
         }
       }
     }
   };
   ```

2. **Rate Limit Monitoring**
   ```javascript
   // Monitor rate limit headers
   const checkRateLimit = (response) => {
     const limit = response.headers.get('X-RateLimit-Limit');
     const remaining = response.headers.get('X-RateLimit-Remaining');
     const reset = response.headers.get('X-RateLimit-Reset');
     
     if (remaining && parseInt(remaining) < 10) {
       console.warn(`Rate limit warning: ${remaining}/${limit} requests remaining`);
     }
     
     return {
       limit: parseInt(limit),
       remaining: parseInt(remaining),
       reset: parseInt(reset)
     };
   };
   ```

### API Request Rate Limiting

**Symptoms:**
- API calls return 429 status codes
- Batch operations fail intermittently
- Performance degradation during high traffic

**Solutions:**

1. **Request Queuing**
   ```javascript
   // Queue API requests to respect rate limits
   class RateLimitedAPI {
     constructor(requestsPerMinute = 100) {
       this.queue = [];
       this.processing = false;
       this.requestsPerMinute = requestsPerMinute;
       this.requestCount = 0;
       this.lastReset = Date.now();
     }

     async makeRequest(url, options = {}) {
       return new Promise((resolve, reject) => {
         this.queue.push({ url, options, resolve, reject });
         this.processQueue();
       });
     }

     async processQueue() {
       if (this.processing || this.queue.length === 0) {
         return;
       }

       this.processing = true;

       while (this.queue.length > 0) {
         // Reset counter if minute has passed
         if (Date.now() - this.lastReset >= 60000) {
           this.requestCount = 0;
           this.lastReset = Date.now();
         }

         // Check if we can make a request
         if (this.requestCount >= this.requestsPerMinute) {
           const waitTime = 60000 - (Date.now() - this.lastReset);
           await new Promise(resolve => setTimeout(resolve, waitTime));
           this.requestCount = 0;
           this.lastReset = Date.now();
         }

         const { url, options, resolve, reject } = this.queue.shift();
         
         try {
           this.requestCount++;
           const response = await fetch(url, options);
           
           if (response.status === 429) {
             const retryAfter = response.headers.get('Retry-After') || 60;
             await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
             this.queue.unshift({ url, options, resolve, reject });
             continue;
           }
           
           resolve(response);
         } catch (error) {
           reject(error);
         }
       }

       this.processing = false;
     }
   }

   // Usage
   const api = new RateLimitedAPI(100);
   const response = await api.makeRequest('https://api.protekt.com/users');
   ```

2. **Batch Request Optimization**
   ```javascript
   // Optimize batch requests to minimize API calls
   const batchUserOperations = async (operations) => {
     const batchSize = 10; // Process 10 operations per request
     const batches = [];
     
     for (let i = 0; i < operations.length; i += batchSize) {
       batches.push(operations.slice(i, i + batchSize));
     }
     
     const results = [];
     
     for (const batch of batches) {
       try {
         const response = await fetch('https://api.protekt.com/users/batch', {
           method: 'POST',
           headers: {
             'Content-Type': 'application/json',
             'Authorization': `Bearer ${token}`
           },
           body: JSON.stringify({ operations: batch })
         });
         
         if (response.status === 429) {
           const retryAfter = response.headers.get('Retry-After') || 60;
           await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
           // Retry this batch
           continue;
         }
         
         const result = await response.json();
         results.push(...result.results);
       } catch (error) {
         console.error('Batch operation failed:', error);
         throw error;
       }
     }
     
     return results;
   };
   ```

## Advanced Rate Limit Management

### Custom Rate Limiting Strategy

```javascript
// Custom rate limiting with different strategies
class AdvancedRateLimiter {
  constructor() {
    this.strategies = {
      'token-bucket': this.tokenBucketStrategy,
      'leaky-bucket': this.leakyBucketStrategy,
      'fixed-window': this.fixedWindowStrategy
    };
  }

  tokenBucketStrategy(requests, capacity, refillRate) {
    let tokens = capacity;
    let lastRefill = Date.now();
    
    return (request) => {
      const now = Date.now();
      const timePassed = now - lastRefill;
      tokens = Math.min(capacity, tokens + (timePassed * refillRate / 1000));
      
      if (tokens >= 1) {
        tokens--;
        return Promise.resolve(request());
      } else {
        const waitTime = (1 - tokens) / refillRate * 1000;
        return new Promise(resolve => setTimeout(() => {
          tokens = 0;
          resolve(this.tokenBucketStrategy(requests, capacity, refillRate)(request));
        }, waitTime));
      }
    };
  }

  leakyBucketStrategy(requests, capacity, leakRate) {
    let bucket = [];
    let lastLeak = Date.now();
    
    return (request) => {
      const now = Date.now();
      const timePassed = now - lastLeak;
      const leaked = Math.floor(timePassed * leakRate / 1000);
      
      bucket = bucket.slice(leaked);
      lastLeak = now;
      
      if (bucket.length < capacity) {
        bucket.push(request);
        return Promise.resolve(request());
      } else {
        return Promise.reject(new Error('Bucket full'));
      }
    };
  }

  fixedWindowStrategy(requests, windowSize, maxRequests) {
    let windowStart = Date.now();
    let requestCount = 0;
    
    return (request) => {
      const now = Date.now();
      
      if (now - windowStart >= windowSize) {
        windowStart = now;
        requestCount = 0;
      }
      
      if (requestCount < maxRequests) {
        requestCount++;
        return Promise.resolve(request());
      } else {
        const waitTime = windowSize - (now - windowStart);
        return new Promise(resolve => setTimeout(() => {
          resolve(this.fixedWindowStrategy(requests, windowSize, maxRequests)(request));
        }, waitTime));
      }
    };
  }
}
```

### Rate Limit Configuration

```javascript
// Configure rate limits for different endpoints
const rateLimitConfig = {
  'auth': {
    strategy: 'token-bucket',
    capacity: 100,
    refillRate: 1.67, // 100 requests per minute
    endpoints: ['/oauth/token', '/oauth/authorize']
  },
  'users': {
    strategy: 'leaky-bucket',
    capacity: 50,
    leakRate: 0.83, // 50 requests per minute
    endpoints: ['/users', '/users/*']
  },
  'organizations': {
    strategy: 'fixed-window',
    windowSize: 60000, // 1 minute
    maxRequests: 500,
    endpoints: ['/organizations', '/organizations/*']
  }
};

// Apply rate limiting based on endpoint
const applyRateLimiting = (endpoint, request) => {
  const config = Object.values(rateLimitConfig).find(c => 
    c.endpoints.some(e => endpoint.includes(e))
  );
  
  if (config) {
    const limiter = new AdvancedRateLimiter();
    const strategy = limiter.strategies[config.strategy];
    return strategy(request, config.capacity, config.refillRate || config.leakRate || config.maxRequests);
  }
  
  return Promise.resolve(request());
};
```

## Error Handling and Recovery

### Graceful Rate Limit Handling

```javascript
// Handle rate limit errors gracefully
const handleRateLimitError = async (error, retryCount = 0) => {
  if (error.status === 429) {
    const retryAfter = error.headers?.get('Retry-After') || 60;
    const maxRetries = 3;
    
    if (retryCount < maxRetries) {
      console.log(`Rate limited. Retrying in ${retryAfter} seconds... (${retryCount + 1}/${maxRetries})`);
      
      await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
      
      // Retry the original request
      return makeRequest(error.originalRequest);
    } else {
      throw new Error('Max retries exceeded for rate limit');
    }
  }
  
  throw error;
};

// Enhanced fetch with rate limit handling
const makeRequest = async (url, options = {}) => {
  try {
    const response = await fetch(url, options);
    
    if (response.status === 429) {
      const error = new Error('Rate limit exceeded');
      error.status = 429;
      error.headers = response.headers;
      error.originalRequest = { url, options };
      throw error;
    }
    
    return response;
  } catch (error) {
    return handleRateLimitError(error);
  }
};
```

### Rate Limit Monitoring and Alerting

```javascript
// Monitor rate limit usage
class RateLimitMonitor {
  constructor() {
    this.metrics = {
      requests: 0,
      rateLimited: 0,
      averageResponseTime: 0
    };
  }

  recordRequest(response, responseTime) {
    this.metrics.requests++;
    this.metrics.averageResponseTime = 
      (this.metrics.averageResponseTime * (this.metrics.requests - 1) + responseTime) / this.metrics.requests;
    
    if (response.status === 429) {
      this.metrics.rateLimited++;
      this.alertRateLimit();
    }
    
    this.checkThresholds();
  }

  alertRateLimit() {
    const rateLimitPercentage = (this.metrics.rateLimited / this.metrics.requests) * 100;
    
    if (rateLimitPercentage > 10) {
      console.warn(`High rate limit percentage: ${rateLimitPercentage.toFixed(2)}%`);
      // Send alert to monitoring system
      this.sendAlert({
        type: 'rate_limit_warning',
        percentage: rateLimitPercentage,
        totalRequests: this.metrics.requests,
        rateLimitedRequests: this.metrics.rateLimited
      });
    }
  }

  checkThresholds() {
    if (this.metrics.requests % 100 === 0) {
      console.log('Rate limit metrics:', this.metrics);
    }
  }

  sendAlert(alert) {
    // Send to monitoring service (e.g., Sentry, DataDog, etc.)
    console.log('Alert:', alert);
  }
}
```

## Best Practices

1. **Always check rate limit headers** in API responses
2. **Implement exponential backoff** for retries
3. **Use request queuing** for high-volume applications
4. **Monitor rate limit usage** and set up alerts
5. **Optimize batch operations** to reduce API calls
6. **Cache responses** when possible to avoid repeated requests
7. **Use appropriate rate limiting strategies** for different endpoints
8. **Handle rate limit errors gracefully** with user-friendly messages
9. **Test rate limiting scenarios** in your development environment
10. **Document rate limits** in your application's error handling

## Support Resources

- **API Documentation**: [https://docs.protekt.com/reference/rate-limits](https://docs.protekt.com/reference/rate-limits)
- **Rate Limit Calculator**: [https://docs.protekt.com/tools/rate-limit-calculator](https://docs.protekt.com/tools/rate-limit-calculator)
- **Support Email**: support@protekt.com
- **Community Forum**: [https://community.protekt.com](https://community.protekt.com) 